\chapter{Introduction}

At its core, machine-learning-driven natural language processing aims to imitate human
intelligence by observing a human perform a given task repeatedly and training from this
data. For example, in order to train a system to recognize whether a given word is the
name of a person, we would first collect a large set of words, labeled as either people or
not. A system would then take this data, and learn a
model
that can then predict, on unseen
words, whether it is a person or not. The great advantage of this framework is that it frees
us from having to have a deep understanding of the underlying process by which humans
perform the target task, instead allowing us to observe examples and use this to learn to
replicate the task. In fact, this has been responsible for much of the progress in natural
language processing in the first two decades of the new millennium. Many of the core
NLP tasks (named entity recognition, part of speech tagging, parsing, etc.) can now be
done with high accuracy, and many of the higher-level tasks (relation extraction, sentiment
analysis, question-answering, etc.) have matured to the point of being useful as off-the-
shelf components both for academia and industry.

At its core, machine-learning-driven natural language processing aims to imitate human
intelligence by observing a human perform a given task repeatedly and training from this
data. For example, in order to train a system to recognize whether a given word is the
name of a person, we would first collect a large set of words, labeled as either people or
not. A system would then take this data, and learn a
model
that can then predict, on unseen
words, whether it is a person or not. The great advantage of this framework is that it frees
us from having to have a deep understanding of the underlying process by which humans
perform the target task, instead allowing us to observe examples and use this to learn to
replicate the task. In fact, this has been responsible for much of the progress in natural
language processing in the first two decades of the new millennium. Many of the core
NLP tasks (named entity recognition, part of speech tagging, parsing, etc.) can now be
done with high accuracy, and many of the higher-level tasks (relation extraction, sentiment
analysis, question-answering, etc.) have matured to the point of being useful as off-the-
shelf components both for academia and industry.

We use Lambda DCS \cite{Liang2013LambdaDC}.
\begin{equation}
x_{1,2} = \frac{-b\pm\sqrt{b^2-4ac}}{2a}
\end{equation}
The way we think is to use $\T{Tom} \sqcap \T{Jerry} + \T{Hello}.\T{Kitty}$ or $a \sqcap b$ and $a \cap b$ or $\B{yay}$.
